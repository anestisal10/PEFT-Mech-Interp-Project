Mechanistic Interpretability of GPT-2 Summarization: Circuit Evolution & PEFT Analysis

This repository contains the code and experimental logs for analyzing the mechanistic evolution of GPT-2 during fine-tuning for summarization (CNN/DailyMail). We utilize Edge Attribution Patching (EAP-IG) to extract task-specific circuits, track their evolution across training checkpoints, and validate their importance using Parameter-Efficient Fine-Tuning (PEFT/LoRA) comparisons.

üß™ Project Overview

The goal of this project is to verify the "edge-centric" nature of fine-tuning and determine if identifying critical mechanistic circuits can inform better PEFT strategies.

Key Methodologies:

Corrupted Data Generation: Using ROUGE-based masking to create causal intervention datasets.

EAP-IG: Extracting computational subgraphs (circuits) responsible for the summarization task.

Differential Analysis: Tracking Hidden State Similarity, Attention KL Divergence, and Entropy shifts.

LoRA Bake-off: Comparing standard LoRA against "Circuit-Targeted" LoRA based on extracted graphs.

üìÇ Repository Structure
1. Data & Training

create_causal_summarization_data.py: Generates the causal dataset (clean/corrupted pairs) based on ROUGE salience. Used for EAP-IG attribution.

run_finetuning_with_checkpoints.py: Fine-tunes GPT-2 on CNN/DailyMail (20k subset), saving checkpoints and latent representations. Implements "Smart Truncation" and correct masking of article tokens.

dataset.py: PyTorch Dataset classes for EAP ingestion.

2. Circuit Extraction & Analysis

extract_summarization_circuit.py: Runs EAP-IG on the model (Base, Fine-tuned, or Checkpoints) to produce .json circuit files (e.g., C_before.json, C_after.json).

analyze_circuit_evolution.py: Visualizes how nodes and edges change across training steps, calculating the unified change rate (
Œî
ùëÜ
ŒîS
).

differential_analysis.py: Performs layer-wise analysis of Hidden State Similarity (RSA), Attention KL Divergence, and Entropy.

evaluate_faithfulness.py: Calculates how well the extracted circuit mimics the full model's performance (KL Divergence comparison).

evaluate_robustness.py: Measures Jaccard similarity between circuits (e.g., Base vs. Fine-tuned).

3. Evaluation & Validation

test_set_evaluation.py: Calculates ROUGE-1/2/L scores for models.

run_peft_bakeoff.py: The final validation step. Trains LoRA adapters targeting specific layers (Standard vs. Paper's Critical Layers vs. Empirically Observed Layers).

4. Library Utilities

attribute.py, evaluate.py, graph.py, metrics.py, visualization.py: Core EAP-IG library components (adapted from FinetuneCircuits).

üìä Key Experimental Results
1. Performance (ROUGE Scores)

We fine-tuned GPT-2 (Small) on 20k samples of CNN/DailyMail. While ROUGE improved, the delta suggests "Weak Fine-Tuning" compared to state-of-the-art fully converged models.

Model	ROUGE-1	ROUGE-2	ROUGE-L
GPT-2 Base	18.15	3.00	12.99
GPT-2 Fine-tuned (20k)	24.80	5.65	16.20
2. Mechanistic Anomaly: The "Shallow Adaptation"

Our differential analysis revealed a fascinating anomaly. Previous literature suggests that summarization fine-tuning causes entropy collapse in middle layers (2, 3, 5). However, our 20k-sample run showed entropy increase and minimal representational drift in those layers.

Layer-wise Differential Analysis:

Layer 11 (Output): Massive hidden state divergence (1.38). The model heavily rewired its output head.

Layers 2, 3, 5 (Middle): Negligible change in hidden states (
1
‚àí
ùëÜ
ùëñ
ùëö
‚âà
0.02
1‚àíSim‚âà0.02
).

Entropy: Increased across all layers (Attention distribution softened rather than sharpened).

Interpretation: The model performed a stylistic, shallow adaptation. It learned how to output a summary format (Layer 11) without fully developing the deep mechanistic "summary circuit" (Layers 2-5) required for complex content extraction.

3. Circuit Faithfulness

Despite the shallow adaptation, the EAP-IG extracted circuits remained highly faithful to the model's logic.

Faithfulness Score: ~89.3% - 92.9%

Robustness (Jaccard): 0.28 (Low similarity between Base and Fine-tuned circuits, confirming task specialization).

4. The PEFT "Bake-off" (Validation)

To prove that the "True" summarization circuit exists in Layers 2, 3, and 5 (as per literature) despite our weak fine-tuning not activating them, we ran LoRA experiments targeting specific layers.

LoRA Strategy	Target Layers	ROUGE-1	ROUGE-L	Interpretation
Standard	All Linear	18.77	15.05	Baseline upper bound.
Targeted (Observed)	9, 10, 11	13.67	10.78	Targeting layers that changed most during our weak FT reinforced the "shallow" bias.
Targeted (Paper)	2, 3, 5	16.04	12.56	Outperformed Observed layers. Proves the intrinsic summarization capability resides here.
Targeted (Hybrid)	5, 10, 11	N/A	N/A	(Recommended Future Work)

Conclusion: The fact that targeting Layers 2, 3, and 5 yielded better results than targeting the layers that actually changed (9, 10, 11) confirms that mechanistic interpretability can identify optimal LoRA targets even when the base fine-tuning is imperfect.

üöÄ How to Run
1. Environment Setup

Ensure you have transformers, torch, datasets, evaluate, and pygraphviz installed.

2. Generate Data

Create the causal dataset for circuit extraction.

code
Bash
download
content_copy
expand_less
python create_causal_summarization_data.py
3. Fine-Tune Model

Train the model and generate checkpoints (adjust subset_train_size in script if needed).

code
Bash
download
content_copy
expand_less
python run_finetuning_with_checkpoints.py
4. Extract Circuits

Run EAP-IG on the Base model and the Fine-tuned model.

code
Bash
download
content_copy
expand_less
# For Base Model (C_before)
python extract_summarization_circuit.py --model_path "gpt2" --output "C_before_summarization.json"

# For Fine-tuned Model (C_after)
python extract_summarization_circuit.py --model_path "model_outputs/gpt2_20k_finetuned" --output "C_after_summarization.json"
5. Analyze Results

Generate differential plots and evolution graphs.

code
Bash
download
content_copy
expand_less
python differential_analysis.py --finetuned_model_path "model_outputs/gpt2_20k_finetuned"
python analyze_circuit_evolution.py
6. Run LoRA Bake-off

Compare the effectiveness of different LoRA targets.

code
Bash
download
content_copy
expand_less
python run_peft_bakeoff.py
üîÆ Future Work

Full Convergence: Re-run fine-tuning on the full 300k dataset with larger batch sizes to observe the predicted "entropy collapse" in middle layers.

Hybrid LoRA: Test a Hybrid Strategy (Layers 5, 10, 11) to balance deep mechanistic reasoning (Layer 5) with output formatting (Layer 11).

Circuit Evolution: Compare the trajectory of C_step_x checkpoints between a "Weak" run and a "Strong" run to visualize the moment deep circuits activate.
